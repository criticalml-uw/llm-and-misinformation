{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from os import environ\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Key and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI(api_key=environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "data = pd.read_excel('chat_prompts.xlsx')\n",
    "data = data.fillna('')\n",
    "\n",
    "tests = [\n",
    "    \"usmle_1_q\"\n",
    "]\n",
    "\n",
    "test_answers = [\n",
    "    \"usmle_1_a\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished question 0 for usmle_1_q\n",
      "Finished question 2 for usmle_1_q\n",
      "Finished question 3 for usmle_1_q\n",
      "Finished question 4 for usmle_1_q\n",
      "Finished question 5 for usmle_1_q\n",
      "Finished question 7 for usmle_1_q\n",
      "Finished question 11 for usmle_1_q\n",
      "Finished question 14 for usmle_1_q\n",
      "Finished question 16 for usmle_1_q\n",
      "Finished question 17 for usmle_1_q\n",
      "Finished question 19 for usmle_1_q\n",
      "Finished question 22 for usmle_1_q\n",
      "Finished question 24 for usmle_1_q\n",
      "Finished question 25 for usmle_1_q\n",
      "Finished question 27 for usmle_1_q\n",
      "Finished question 30 for usmle_1_q\n",
      "Finished question 34 for usmle_1_q\n",
      "Finished question 35 for usmle_1_q\n",
      "Finished question 36 for usmle_1_q\n",
      "Finished question 38 for usmle_1_q\n",
      "Finished question 44 for usmle_1_q\n",
      "Finished question 45 for usmle_1_q\n",
      "Finished question 47 for usmle_1_q\n",
      "Finished question 50 for usmle_1_q\n",
      "Finished question 53 for usmle_1_q\n",
      "Finished question 54 for usmle_1_q\n",
      "Finished question 55 for usmle_1_q\n",
      "Finished question 57 for usmle_1_q\n",
      "Finished question 65 for usmle_1_q\n",
      "Finished question 67 for usmle_1_q\n",
      "Finished question 68 for usmle_1_q\n",
      "Finished question 74 for usmle_1_q\n",
      "Finished question 76 for usmle_1_q\n",
      "Finished question 77 for usmle_1_q\n",
      "Finished question 78 for usmle_1_q\n",
      "Finished question 79 for usmle_1_q\n",
      "Finished question 80 for usmle_1_q\n",
      "Finished question 84 for usmle_1_q\n",
      "Finished question 89 for usmle_1_q\n"
     ]
    }
   ],
   "source": [
    "for item, test in enumerate(tests):\n",
    "    for idx, row in enumerate(data.itertuples()):\n",
    "        if getattr(row, \"ne_match\") != \"CCC\" and getattr(row, \"ex_match\") != \"CCC\":\n",
    "            continue\n",
    "        with open(\"results_sent_drop.csv\", mode=\"a\", encoding=\"UTF8\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            csv_out = []\n",
    "            csv_out.append(idx)\n",
    "\n",
    "            prompt = getattr(row, test)\n",
    "\n",
    "            # Remove multiple choice options, making question open-ended\n",
    "            prompt = prompt.split(\"(A)\")\n",
    "            prompt = prompt[0]\n",
    "            prompt = prompt.replace(\"which of the following\", \"what\")\n",
    "            prompt = prompt.replace(\"Which of the following\", \"What\")\n",
    "\n",
    "            # Split question into sentences\n",
    "            prompt_split = prompt.split(\". \")\n",
    "            for id, sentence in enumerate(prompt_split):\n",
    "                if (id + 2) >= len(prompt_split) and \"?\" in sentence:\n",
    "                    break\n",
    "                else:\n",
    "                    temp_prompt = prompt_split\n",
    "                    temp_prompt = temp_prompt[:id] + temp_prompt[id+1:]\n",
    "\n",
    "                    sentence_drop_prompt = \". \".join(temp_prompt)\n",
    "\n",
    "                    question = f\"Including an explanation, answer the following question: {sentence_drop_prompt}\"\n",
    "                    copmpletion = client.chat.completions.create(\n",
    "                        model=\"gpt-4\",\n",
    "                        messages=[{\"role\": \"system\", \"content\": question}],\n",
    "                        max_tokens=2048,\n",
    "                        n=1,\n",
    "                        stop=None,\n",
    "                        temperature=0,\n",
    "                        top_p=1,\n",
    "                        frequency_penalty=0,\n",
    "                        presence_penalty=0\n",
    "                    )\n",
    "\n",
    "                    gpt_ans = copmpletion.choices[0].message.content.strip()\n",
    "                    gpt_ans = \" \".join(gpt_ans.splitlines())\n",
    "                    data.at[idx, f\"{test_answers[item]}_{id}\"] = gpt_ans\n",
    "                    csv_out.append(gpt_ans)\n",
    "                    time.sleep(4)\n",
    "\n",
    "            writer.writerow(csv_out)\n",
    "            print(f\"Finished question {idx} for {test}\")\n",
    "\n",
    "    data.to_excel(f\"output_results_sent_drop.xlsx\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
